{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Training and Evaluation of GNNs and LLMs\n",
                "In this notebook, we train the models on the [MovieLens Dataset](https://movielens.org/) after the Pytorch Geometrics Tutorial on [Link Prediction](https://colab.research.google.com/drive/1xpzn1Nvai1ygd_P5Yambc_oe4VBPK_ZT?usp=sharing#scrollTo=vit8xKCiXAue).\n",
                "\n",
                "First we import all of our dependencies.\n",
                "\n",
                "The **GraphRepresentationGenerator** manages and trains a GNN model. Its most important interfaces include\n",
                "**the constructor**, which defines the GNN architecture and loads the pre-trained GNN model if it is already on the hard disk,\n",
                "**the training method**, which initializes the training on the GNN model and\n",
                "**the get_embedding methods**, which represent the inference interface to the GNN model and return the corresponding embeddings in the dimension defined in the constructor for given user movie node pairs.\n",
                "\n",
                "**The MovieLensLoader** loads and manages the data sets. The most important tasks include **saving and (re)loading and transforming** the data sets.\n",
                "\n",
                "**PromptEncoderOnlyClassifier** and **VanillaEncoderOnlyClassifier** each manage a **prompt (model) LLM** and a **vanilla (model) LLM**. An EncoderOnlyClassifier (ClassifierBase) provides interfaces for training and testing an LLM model.\n",
                "PromptEncoder and VanillaEncoder differ from their DataCollectors. DataCollectors change the behavior of the models during training and testing and allow data points to be created at runtime. With the help of these collators, we **create non-existent edges on the fly**."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "from graph_representation_generator.graph_representation_generator import (\n",
                "    GraphRepresentationGenerator,\n",
                ")\n",
                "from dataset_manager.movie_lens_manager import MovieLensManager\n",
                "from dataset_manager.kg_manager import ROOT\n",
                "from llm_manager.graph_prompter_hf.classifier import GraphPrompterHF"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "MODEL_NAME = \"google/bert_uncased_L-2_H-128_A-2\"\n",
                "EPOCHS = 10\n",
                "BATCH_SIZE_LLM = 256"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "We define in advance which **Knowledge Graph Embedding Dimension (KGE_DIMENSION)** the GNN encoder has. We want to determine from which output dimension the GNN encoder can produce embeddings that lead to a significant increase in performance *without exceeding the context length of the LLMs*. In the original tutorial, the KGE_DIMENSION was $64$."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": [
                "kg_manager = MovieLensManager()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "llm_df = kg_manager.llm_df.merge(kg_manager.target_df[[\"id\", \"prompt_feature_title\", \"prompt_feature_genres\"]].rename(columns={\"id\": \"target_id\"}), on = \"target_id\")\n",
                "llm_df"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "First we load the MovieLensLoader, which downloads the Movie Lens dataset (https://files.grouplens.org/datasets/movielens/ml-32m.zip) and prepares it to be used on GNN and LLM. We also pass the embedding dimensions that we will assume we are training with. First time takes approx. 30 sec."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "HeteroData(\n",
                            "  source={ node_id=[610] },\n",
                            "  target={\n",
                            "    node_id=[9742],\n",
                            "    x=[9742, 20],\n",
                            "  },\n",
                            "  (source, edge, target)={ edge_index=[2, 100836] },\n",
                            "  (target, rev_edge, source)={ edge_index=[2, 100836] }\n",
                            ")"
                        ]
                    },
                    "execution_count": 4,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "kg_manager.data"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Next, we initialize the GNN trainers (possible on Cuda), one for each KGE_DIMENSION.\n",
                "A GNN trainer manages a model and each model consists of an **encoder and classifier** part.\n",
                "\n",
                "**The encoder** is a parameterized *Grap Convolutional Network (GCN)* with a *2-layer GNN computation graph* and a single *ReLU* activation function in between.\n",
                "\n",
                "**The classifier** applies the dot-product between source and destination kges to derive edge-level predictions."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "loading pretrained model\n",
                        "Device: 'cuda'\n"
                    ]
                }
            ],
            "source": [
                "graph_representation_generator_graph_prompter_hf = GraphRepresentationGenerator(\n",
                "    kg_manager.data.to(\"cuda\"),\n",
                "    kg_manager.gnn_train_data.to(\"cuda\"),\n",
                "    kg_manager.gnn_val_data.to(\"cuda\"),\n",
                "    kg_manager.gnn_test_data.to(\"cuda\"),\n",
                "    hidden_channels=128,\n",
                "    kge_dimension=128,\n",
                "    force_recompute=False,\n",
                "    device=\"cuda\",\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Next we produce the KGEs for every edge in the dataset. These embeddings can then be used for the LLM on the link-prediction task."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Next we initialize the vanilla encoder only classifier. This classifier does only use the NLP part of the prompt (no KGE) for predicting if the given link exists."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Some weights of GraphPrompterHFBertForSequenceClassification were not initialized from the model checkpoint at ./data/llm/vanilla/training/best and are newly initialized because the shapes did not match:\n",
                        "- bert.embeddings.token_type_embeddings.weight: found shape torch.Size([3, 128]) in the checkpoint and torch.Size([5, 128]) in the model instantiated\n",
                        "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "device cuda\n",
                        "5\n",
                        "5\n",
                        "5\n"
                    ]
                }
            ],
            "source": [
                "graph_prompter_hf_bert_classifier = GraphPrompterHF(\n",
                "    kge_manager=kg_manager,\n",
                "    get_embeddings_cb=graph_representation_generator_graph_prompter_hf.get_embeddings,\n",
                "    model_name=MODEL_NAME,\n",
                "    vanilla_model_path=f\"{ROOT}/llm/vanilla/training/best\",\n",
                "    # gnn_parameters=list(\n",
                "    #     graph_representation_generator_graph_prompter_hf.model.parameters()\n",
                "    # ),\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [],
            "source": [
                "dataset_embedding = kg_manager.generate_graph_prompter_hf_embedding_dataset(\n",
                "    graph_prompter_hf_bert_classifier.tokenizer.sep_token,\n",
                "    graph_prompter_hf_bert_classifier.tokenizer.pad_token,\n",
                "    graph_prompter_hf_bert_classifier.tokenize_function,\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "import torch\n",
                "\n",
                "gnn_model = graph_representation_generator_graph_prompter_hf.model\n",
                "trainer = graph_prompter_hf_bert_classifier._get_trainer(\n",
                "    dataset_embedding, epochs=EPOCHS, batch_size=BATCH_SIZE_LLM\n",
                ")\n",
                "optimizer = torch.optim.SGD(\n",
                "    list(trainer.model.parameters()) + list(gnn_model.parameters()),\n",
                "    lr=0.001,\n",
                "    momentum=0.9,\n",
                ")\n",
                "\n",
                "\n",
                "def inspect_gradients(trainer, batch):\n",
                "    optimizer.zero_grad()  # Clear previous gradients\n",
                "    trainer.model.eval()  # Set model to eval mode (no dropout, etc.)\n",
                "    outputs = trainer.model(**batch)\n",
                "    loss = outputs.loss\n",
                "    loss.backward()  # Run backward to compute gradients\n",
                "    optimizer.step()\n",
                "    for name, param in gnn_model.named_parameters():\n",
                "        if param.requires_grad and param.grad is not None:\n",
                "            print(f\"Gradient for gnn {name}: {param.grad}\")\n",
                "\n",
                "    # for name, param in trainer.model.named_parameters():\n",
                "    #     if param.requires_grad and param.grad is not None:\n",
                "    #         print(f\"Gradient for LLM{name}: {(param.grad > 0).any()}\")\n",
                "\n",
                "\n",
                "# Example of grabbing a batch and inspecting gradients\n",
                "for i in range(1):\n",
                "    sample_batch = next(iter(trainer.get_train_dataloader()))\n",
                "\n",
                "    inspect_gradients(trainer, sample_batch)\n",
                "\n",
                "tens_1 = graph_representation_generator_graph_prompter_hf.model.to(\n",
                "    device=\"cpu\"\n",
                ").state_dict()\n",
                "\n",
                "tens_2 = torch.load(\"./data/gnn/backup/model_128.pth\")\n",
                "same = True\n",
                "for key in tens_1.keys():\n",
                "    if isinstance(tens_1[key], torch.Tensor):\n",
                "        if not (tens_1[key] == tens_2[key]).all():\n",
                "            same = False\n",
                "print(same)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "990f2f8737444980aedf87544ee7eb57",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/2210 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "c:\\Users\\MARS\\.conda\\envs\\hauptprojekt\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:440: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at ..\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:455.)\n",
                        "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "{'loss': 0.5269, 'grad_norm': 2.356945753097534, 'learning_rate': 1.0000000000000002e-06, 'epoch': 0.05}\n",
                        "{'loss': 0.5371, 'grad_norm': 1.5672634840011597, 'learning_rate': 2.0000000000000003e-06, 'epoch': 0.09}\n",
                        "{'loss': 0.5213, 'grad_norm': 1.6135259866714478, 'learning_rate': 3e-06, 'epoch': 0.14}\n",
                        "{'loss': 0.5222, 'grad_norm': 1.489190936088562, 'learning_rate': 4.000000000000001e-06, 'epoch': 0.18}\n",
                        "{'loss': 0.5401, 'grad_norm': 1.5681816339492798, 'learning_rate': 5e-06, 'epoch': 0.23}\n",
                        "{'loss': 0.5172, 'grad_norm': 2.9827609062194824, 'learning_rate': 6e-06, 'epoch': 0.27}\n",
                        "{'loss': 0.5017, 'grad_norm': 1.6629126071929932, 'learning_rate': 7.000000000000001e-06, 'epoch': 0.32}\n",
                        "{'loss': 0.5083, 'grad_norm': 1.4409894943237305, 'learning_rate': 8.000000000000001e-06, 'epoch': 0.36}\n",
                        "{'loss': 0.4976, 'grad_norm': 1.8311820030212402, 'learning_rate': 9e-06, 'epoch': 0.41}\n",
                        "{'loss': 0.5188, 'grad_norm': 1.9138226509094238, 'learning_rate': 1e-05, 'epoch': 0.45}\n",
                        "{'loss': 0.4989, 'grad_norm': 1.5469721555709839, 'learning_rate': 1.1000000000000001e-05, 'epoch': 0.5}\n",
                        "{'loss': 0.496, 'grad_norm': 2.0365357398986816, 'learning_rate': 1.2e-05, 'epoch': 0.54}\n",
                        "{'loss': 0.5009, 'grad_norm': 3.0413501262664795, 'learning_rate': 1.3000000000000001e-05, 'epoch': 0.59}\n",
                        "{'loss': 0.4869, 'grad_norm': 2.091358184814453, 'learning_rate': 1.4000000000000001e-05, 'epoch': 0.63}\n",
                        "{'loss': 0.5098, 'grad_norm': 2.160606622695923, 'learning_rate': 1.5e-05, 'epoch': 0.68}\n",
                        "{'loss': 0.4837, 'grad_norm': 1.5626108646392822, 'learning_rate': 1.6000000000000003e-05, 'epoch': 0.72}\n",
                        "{'loss': 0.5165, 'grad_norm': 2.182589054107666, 'learning_rate': 1.7000000000000003e-05, 'epoch': 0.77}\n",
                        "{'loss': 0.4751, 'grad_norm': 1.467013955116272, 'learning_rate': 1.8e-05, 'epoch': 0.81}\n",
                        "{'loss': 0.4957, 'grad_norm': 1.9928553104400635, 'learning_rate': 1.9e-05, 'epoch': 0.86}\n",
                        "{'loss': 0.4708, 'grad_norm': 2.0082595348358154, 'learning_rate': 2e-05, 'epoch': 0.9}\n",
                        "{'loss': 0.46, 'grad_norm': 1.9982823133468628, 'learning_rate': 2.1e-05, 'epoch': 0.95}\n",
                        "{'loss': 0.4867, 'grad_norm': 2.3070740699768066, 'learning_rate': 2.2000000000000003e-05, 'epoch': 1.0}\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "f81a8942e1434b2f95ece9b87fb6ecd3",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/79 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "{'eval_loss': 0.4471861720085144, 'eval_accuracy': 0.7947535455717545, 'eval_runtime': 25.024, 'eval_samples_per_second': 805.866, 'eval_steps_per_second': 3.157, 'epoch': 1.0}\n",
                        "{'loss': 0.4708, 'grad_norm': 1.9528943300247192, 'learning_rate': 2.3000000000000003e-05, 'epoch': 1.04}\n",
                        "{'loss': 0.4581, 'grad_norm': 1.5401691198349, 'learning_rate': 2.4e-05, 'epoch': 1.09}\n",
                        "{'loss': 0.4641, 'grad_norm': 2.118473768234253, 'learning_rate': 2.5e-05, 'epoch': 1.13}\n",
                        "{'loss': 0.4826, 'grad_norm': 1.5756334066390991, 'learning_rate': 2.6000000000000002e-05, 'epoch': 1.18}\n",
                        "{'loss': 0.4911, 'grad_norm': 1.8010320663452148, 'learning_rate': 2.7000000000000002e-05, 'epoch': 1.22}\n",
                        "{'loss': 0.4987, 'grad_norm': 1.6645898818969727, 'learning_rate': 2.8000000000000003e-05, 'epoch': 1.27}\n",
                        "{'loss': 0.4798, 'grad_norm': 1.5093493461608887, 'learning_rate': 2.9e-05, 'epoch': 1.31}\n",
                        "{'loss': 0.4719, 'grad_norm': 1.4097771644592285, 'learning_rate': 3e-05, 'epoch': 1.36}\n",
                        "{'loss': 0.4622, 'grad_norm': 1.8373453617095947, 'learning_rate': 3.1e-05, 'epoch': 1.4}\n",
                        "{'loss': 0.4693, 'grad_norm': 1.814962387084961, 'learning_rate': 3.2000000000000005e-05, 'epoch': 1.45}\n",
                        "{'loss': 0.456, 'grad_norm': 1.445093035697937, 'learning_rate': 3.3e-05, 'epoch': 1.49}\n",
                        "{'loss': 0.4643, 'grad_norm': 1.7924613952636719, 'learning_rate': 3.4000000000000007e-05, 'epoch': 1.54}\n",
                        "{'loss': 0.4614, 'grad_norm': 2.9022414684295654, 'learning_rate': 3.5e-05, 'epoch': 1.58}\n",
                        "{'loss': 0.4507, 'grad_norm': 2.0958828926086426, 'learning_rate': 3.6e-05, 'epoch': 1.63}\n",
                        "{'loss': 0.4496, 'grad_norm': 1.4466018676757812, 'learning_rate': 3.7e-05, 'epoch': 1.67}\n",
                        "{'loss': 0.448, 'grad_norm': 1.981345772743225, 'learning_rate': 3.8e-05, 'epoch': 1.72}\n",
                        "{'loss': 0.478, 'grad_norm': 1.577515959739685, 'learning_rate': 3.9000000000000006e-05, 'epoch': 1.76}\n",
                        "{'loss': 0.4657, 'grad_norm': 1.5284041166305542, 'learning_rate': 4e-05, 'epoch': 1.81}\n",
                        "{'loss': 0.4539, 'grad_norm': 1.9010902643203735, 'learning_rate': 4.1e-05, 'epoch': 1.86}\n",
                        "{'loss': 0.4495, 'grad_norm': 1.809432029724121, 'learning_rate': 4.2e-05, 'epoch': 1.9}\n",
                        "{'loss': 0.4497, 'grad_norm': 2.4999775886535645, 'learning_rate': 4.3e-05, 'epoch': 1.95}\n",
                        "{'loss': 0.4217, 'grad_norm': 1.4763975143432617, 'learning_rate': 4.4000000000000006e-05, 'epoch': 1.99}\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "d9a5265eb03647aeac2a2059e41cefb2",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/79 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "{'eval_loss': 0.42714816331863403, 'eval_accuracy': 0.8101755429931567, 'eval_runtime': 24.5838, 'eval_samples_per_second': 820.295, 'eval_steps_per_second': 3.213, 'epoch': 2.0}\n",
                        "{'loss': 0.4519, 'grad_norm': 1.218858242034912, 'learning_rate': 4.5e-05, 'epoch': 2.04}\n",
                        "{'loss': 0.4351, 'grad_norm': 1.6379311084747314, 'learning_rate': 4.600000000000001e-05, 'epoch': 2.08}\n",
                        "{'loss': 0.4121, 'grad_norm': 1.7002352476119995, 'learning_rate': 4.7e-05, 'epoch': 2.13}\n",
                        "{'loss': 0.4313, 'grad_norm': 1.4522855281829834, 'learning_rate': 4.8e-05, 'epoch': 2.17}\n",
                        "{'loss': 0.4228, 'grad_norm': 1.6800661087036133, 'learning_rate': 4.9e-05, 'epoch': 2.22}\n",
                        "{'loss': 0.4292, 'grad_norm': 1.2938059568405151, 'learning_rate': 5e-05, 'epoch': 2.26}\n",
                        "{'loss': 0.4141, 'grad_norm': 2.1415436267852783, 'learning_rate': 4.970760233918128e-05, 'epoch': 2.31}\n",
                        "{'loss': 0.4223, 'grad_norm': 1.5179517269134521, 'learning_rate': 4.941520467836258e-05, 'epoch': 2.35}\n",
                        "{'loss': 0.3911, 'grad_norm': 1.2165006399154663, 'learning_rate': 4.912280701754386e-05, 'epoch': 2.4}\n",
                        "{'loss': 0.4133, 'grad_norm': 1.335942268371582, 'learning_rate': 4.883040935672515e-05, 'epoch': 2.44}\n",
                        "{'loss': 0.4039, 'grad_norm': 1.5060094594955444, 'learning_rate': 4.853801169590643e-05, 'epoch': 2.49}\n",
                        "{'loss': 0.3988, 'grad_norm': 1.5882879495620728, 'learning_rate': 4.824561403508772e-05, 'epoch': 2.53}\n",
                        "{'loss': 0.3908, 'grad_norm': 2.481351137161255, 'learning_rate': 4.7953216374269006e-05, 'epoch': 2.58}\n",
                        "{'loss': 0.3996, 'grad_norm': 1.178809404373169, 'learning_rate': 4.7660818713450294e-05, 'epoch': 2.62}\n",
                        "{'loss': 0.3851, 'grad_norm': 1.2304238080978394, 'learning_rate': 4.736842105263158e-05, 'epoch': 2.67}\n",
                        "{'loss': 0.3824, 'grad_norm': 1.0879237651824951, 'learning_rate': 4.707602339181287e-05, 'epoch': 2.71}\n",
                        "{'loss': 0.3909, 'grad_norm': 1.1353416442871094, 'learning_rate': 4.678362573099415e-05, 'epoch': 2.76}\n",
                        "{'loss': 0.3785, 'grad_norm': 1.811286449432373, 'learning_rate': 4.649122807017544e-05, 'epoch': 2.81}\n",
                        "{'loss': 0.3777, 'grad_norm': 1.1707438230514526, 'learning_rate': 4.619883040935672e-05, 'epoch': 2.85}\n",
                        "{'loss': 0.3826, 'grad_norm': 1.7451846599578857, 'learning_rate': 4.590643274853802e-05, 'epoch': 2.9}\n",
                        "{'loss': 0.3839, 'grad_norm': 1.116660475730896, 'learning_rate': 4.56140350877193e-05, 'epoch': 2.94}\n",
                        "{'loss': 0.3828, 'grad_norm': 1.1803464889526367, 'learning_rate': 4.5321637426900585e-05, 'epoch': 2.99}\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "d9af294a1ba545bfa4732443f8b53966",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/79 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "{'eval_loss': 0.43795621395111084, 'eval_accuracy': 0.8077952990181494, 'eval_runtime': 24.9395, 'eval_samples_per_second': 808.595, 'eval_steps_per_second': 3.168, 'epoch': 3.0}\n",
                        "{'loss': 0.3787, 'grad_norm': 1.4015698432922363, 'learning_rate': 4.502923976608187e-05, 'epoch': 3.03}\n",
                        "{'loss': 0.362, 'grad_norm': 1.104804277420044, 'learning_rate': 4.473684210526316e-05, 'epoch': 3.08}\n",
                        "{'loss': 0.3749, 'grad_norm': 1.0255039930343628, 'learning_rate': 4.4444444444444447e-05, 'epoch': 3.12}\n",
                        "{'loss': 0.3664, 'grad_norm': 1.6047710180282593, 'learning_rate': 4.4152046783625734e-05, 'epoch': 3.17}\n",
                        "{'loss': 0.3766, 'grad_norm': 0.9539791345596313, 'learning_rate': 4.3859649122807014e-05, 'epoch': 3.21}\n",
                        "{'loss': 0.3673, 'grad_norm': 1.4504117965698242, 'learning_rate': 4.356725146198831e-05, 'epoch': 3.26}\n",
                        "{'loss': 0.3835, 'grad_norm': 1.2534492015838623, 'learning_rate': 4.327485380116959e-05, 'epoch': 3.3}\n",
                        "{'loss': 0.365, 'grad_norm': 0.9371690154075623, 'learning_rate': 4.298245614035088e-05, 'epoch': 3.35}\n",
                        "{'loss': 0.3811, 'grad_norm': 2.185962438583374, 'learning_rate': 4.269005847953216e-05, 'epoch': 3.39}\n",
                        "{'loss': 0.3707, 'grad_norm': 1.3096668720245361, 'learning_rate': 4.239766081871345e-05, 'epoch': 3.44}\n",
                        "{'loss': 0.3901, 'grad_norm': 1.2970815896987915, 'learning_rate': 4.210526315789474e-05, 'epoch': 3.48}\n",
                        "{'loss': 0.3658, 'grad_norm': 0.996406078338623, 'learning_rate': 4.1812865497076025e-05, 'epoch': 3.53}\n",
                        "{'loss': 0.3668, 'grad_norm': 1.2137693166732788, 'learning_rate': 4.152046783625731e-05, 'epoch': 3.57}\n",
                        "{'loss': 0.3823, 'grad_norm': 1.0286524295806885, 'learning_rate': 4.12280701754386e-05, 'epoch': 3.62}\n",
                        "{'loss': 0.3876, 'grad_norm': 1.2414369583129883, 'learning_rate': 4.093567251461988e-05, 'epoch': 3.67}\n",
                        "{'loss': 0.3643, 'grad_norm': 1.9560786485671997, 'learning_rate': 4.0643274853801174e-05, 'epoch': 3.71}\n",
                        "{'loss': 0.3711, 'grad_norm': 0.9718953371047974, 'learning_rate': 4.0350877192982455e-05, 'epoch': 3.76}\n",
                        "{'loss': 0.3757, 'grad_norm': 1.164488434791565, 'learning_rate': 4.005847953216375e-05, 'epoch': 3.8}\n",
                        "{'loss': 0.3688, 'grad_norm': 0.9563894271850586, 'learning_rate': 3.976608187134503e-05, 'epoch': 3.85}\n",
                        "{'loss': 0.3812, 'grad_norm': 1.1724344491958618, 'learning_rate': 3.9473684210526316e-05, 'epoch': 3.89}\n",
                        "{'loss': 0.3637, 'grad_norm': 0.9180887937545776, 'learning_rate': 3.9181286549707604e-05, 'epoch': 3.94}\n",
                        "{'loss': 0.3741, 'grad_norm': 1.2145397663116455, 'learning_rate': 3.888888888888889e-05, 'epoch': 3.98}\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "4a520b350588422998f4ca49d5e3c90f",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/79 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "{'eval_loss': 0.446559876203537, 'eval_accuracy': 0.8072498264405434, 'eval_runtime': 25.0322, 'eval_samples_per_second': 805.601, 'eval_steps_per_second': 3.156, 'epoch': 4.0}\n",
                        "{'loss': 0.3584, 'grad_norm': 1.0728813409805298, 'learning_rate': 3.859649122807018e-05, 'epoch': 4.03}\n",
                        "{'loss': 0.3543, 'grad_norm': 1.05841863155365, 'learning_rate': 3.8304093567251465e-05, 'epoch': 4.07}\n",
                        "{'loss': 0.3462, 'grad_norm': 2.6009328365325928, 'learning_rate': 3.8011695906432746e-05, 'epoch': 4.12}\n",
                        "{'loss': 0.3666, 'grad_norm': 2.347879409790039, 'learning_rate': 3.771929824561404e-05, 'epoch': 4.16}\n",
                        "{'loss': 0.3618, 'grad_norm': 1.3307218551635742, 'learning_rate': 3.742690058479532e-05, 'epoch': 4.21}\n",
                        "{'loss': 0.3655, 'grad_norm': 1.3149256706237793, 'learning_rate': 3.713450292397661e-05, 'epoch': 4.25}\n",
                        "{'loss': 0.3751, 'grad_norm': 1.0385316610336304, 'learning_rate': 3.6842105263157895e-05, 'epoch': 4.3}\n",
                        "{'loss': 0.3584, 'grad_norm': 1.8604456186294556, 'learning_rate': 3.654970760233918e-05, 'epoch': 4.34}\n",
                        "{'loss': 0.3434, 'grad_norm': 1.4146934747695923, 'learning_rate': 3.625730994152047e-05, 'epoch': 4.39}\n",
                        "{'loss': 0.356, 'grad_norm': 1.2370762825012207, 'learning_rate': 3.5964912280701756e-05, 'epoch': 4.43}\n",
                        "{'loss': 0.3606, 'grad_norm': 1.9858554601669312, 'learning_rate': 3.5672514619883044e-05, 'epoch': 4.48}\n",
                        "{'loss': 0.3513, 'grad_norm': 1.112059235572815, 'learning_rate': 3.538011695906433e-05, 'epoch': 4.52}\n",
                        "{'loss': 0.3617, 'grad_norm': 1.0684599876403809, 'learning_rate': 3.508771929824561e-05, 'epoch': 4.57}\n",
                        "{'loss': 0.3573, 'grad_norm': 0.933783233165741, 'learning_rate': 3.4795321637426905e-05, 'epoch': 4.62}\n",
                        "{'loss': 0.3896, 'grad_norm': 1.424142837524414, 'learning_rate': 3.4502923976608186e-05, 'epoch': 4.66}\n",
                        "{'loss': 0.3598, 'grad_norm': 0.9957103133201599, 'learning_rate': 3.421052631578947e-05, 'epoch': 4.71}\n",
                        "{'loss': 0.3608, 'grad_norm': 2.04030442237854, 'learning_rate': 3.391812865497076e-05, 'epoch': 4.75}\n",
                        "{'loss': 0.3677, 'grad_norm': 1.0690739154815674, 'learning_rate': 3.362573099415205e-05, 'epoch': 4.8}\n",
                        "{'loss': 0.3256, 'grad_norm': 1.0679000616073608, 'learning_rate': 3.3333333333333335e-05, 'epoch': 4.84}\n",
                        "{'loss': 0.3625, 'grad_norm': 1.16996431350708, 'learning_rate': 3.304093567251462e-05, 'epoch': 4.89}\n",
                        "{'loss': 0.3754, 'grad_norm': 0.8611240386962891, 'learning_rate': 3.274853801169591e-05, 'epoch': 4.93}\n",
                        "{'loss': 0.3836, 'grad_norm': 0.9610282182693481, 'learning_rate': 3.24561403508772e-05, 'epoch': 4.98}\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "8ec0ac5e993a4364b13f62105dcdd7de",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/79 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "{'eval_loss': 0.41634413599967957, 'eval_accuracy': 0.8172666865020332, 'eval_runtime': 25.189, 'eval_samples_per_second': 800.587, 'eval_steps_per_second': 3.136, 'epoch': 5.0}\n",
                        "{'loss': 0.3565, 'grad_norm': 1.014685034751892, 'learning_rate': 3.216374269005848e-05, 'epoch': 5.02}\n",
                        "{'loss': 0.3494, 'grad_norm': 2.0072522163391113, 'learning_rate': 3.187134502923977e-05, 'epoch': 5.07}\n",
                        "{'loss': 0.3653, 'grad_norm': 0.9394254088401794, 'learning_rate': 3.157894736842105e-05, 'epoch': 5.11}\n",
                        "{'loss': 0.3474, 'grad_norm': 1.1360124349594116, 'learning_rate': 3.128654970760234e-05, 'epoch': 5.16}\n",
                        "{'loss': 0.3462, 'grad_norm': 1.221805453300476, 'learning_rate': 3.0994152046783626e-05, 'epoch': 5.2}\n",
                        "{'loss': 0.3491, 'grad_norm': 0.900860071182251, 'learning_rate': 3.0701754385964913e-05, 'epoch': 5.25}\n",
                        "{'loss': 0.3505, 'grad_norm': 1.3020353317260742, 'learning_rate': 3.0409356725146197e-05, 'epoch': 5.29}\n",
                        "{'loss': 0.3357, 'grad_norm': 1.1526535749435425, 'learning_rate': 3.0116959064327488e-05, 'epoch': 5.34}\n",
                        "{'loss': 0.3627, 'grad_norm': 1.683192253112793, 'learning_rate': 2.9824561403508772e-05, 'epoch': 5.38}\n",
                        "{'loss': 0.3707, 'grad_norm': 1.028283953666687, 'learning_rate': 2.9532163742690062e-05, 'epoch': 5.43}\n",
                        "{'loss': 0.353, 'grad_norm': 0.9491552710533142, 'learning_rate': 2.9239766081871346e-05, 'epoch': 5.48}\n",
                        "{'loss': 0.3521, 'grad_norm': 1.7324367761611938, 'learning_rate': 2.8947368421052634e-05, 'epoch': 5.52}\n",
                        "{'loss': 0.3579, 'grad_norm': 1.5494117736816406, 'learning_rate': 2.8654970760233917e-05, 'epoch': 5.57}\n",
                        "{'loss': 0.3506, 'grad_norm': 0.8928989768028259, 'learning_rate': 2.8362573099415208e-05, 'epoch': 5.61}\n",
                        "{'loss': 0.3406, 'grad_norm': 1.7262797355651855, 'learning_rate': 2.8070175438596492e-05, 'epoch': 5.66}\n",
                        "{'loss': 0.3522, 'grad_norm': 1.424363136291504, 'learning_rate': 2.777777777777778e-05, 'epoch': 5.7}\n",
                        "{'loss': 0.3587, 'grad_norm': 0.8332640528678894, 'learning_rate': 2.7485380116959063e-05, 'epoch': 5.75}\n",
                        "{'loss': 0.3615, 'grad_norm': 1.7014487981796265, 'learning_rate': 2.7192982456140354e-05, 'epoch': 5.79}\n",
                        "{'loss': 0.3434, 'grad_norm': 1.1243394613265991, 'learning_rate': 2.6900584795321637e-05, 'epoch': 5.84}\n",
                        "{'loss': 0.3493, 'grad_norm': 0.9869306087493896, 'learning_rate': 2.6608187134502928e-05, 'epoch': 5.88}\n",
                        "{'loss': 0.3572, 'grad_norm': 1.4390103816986084, 'learning_rate': 2.6315789473684212e-05, 'epoch': 5.93}\n",
                        "{'loss': 0.3711, 'grad_norm': 1.4213008880615234, 'learning_rate': 2.60233918128655e-05, 'epoch': 5.97}\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "d152696eddbb453592a506427973f4fe",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/79 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "{'eval_loss': 0.39031901955604553, 'eval_accuracy': 0.8302092631161361, 'eval_runtime': 25.1707, 'eval_samples_per_second': 801.171, 'eval_steps_per_second': 3.139, 'epoch': 6.0}\n",
                        "{'loss': 0.3667, 'grad_norm': 0.9571056365966797, 'learning_rate': 2.5730994152046783e-05, 'epoch': 6.02}\n",
                        "{'loss': 0.3373, 'grad_norm': 1.0787596702575684, 'learning_rate': 2.5438596491228074e-05, 'epoch': 6.06}\n",
                        "{'loss': 0.3454, 'grad_norm': 1.437703251838684, 'learning_rate': 2.5146198830409358e-05, 'epoch': 6.11}\n",
                        "{'loss': 0.341, 'grad_norm': 1.6450515985488892, 'learning_rate': 2.485380116959064e-05, 'epoch': 6.15}\n",
                        "{'loss': 0.3619, 'grad_norm': 1.2445870637893677, 'learning_rate': 2.456140350877193e-05, 'epoch': 6.2}\n",
                        "{'loss': 0.3689, 'grad_norm': 1.0084528923034668, 'learning_rate': 2.4269005847953216e-05, 'epoch': 6.24}\n",
                        "{'loss': 0.3344, 'grad_norm': 1.0685068368911743, 'learning_rate': 2.3976608187134503e-05, 'epoch': 6.29}\n",
                        "{'loss': 0.3555, 'grad_norm': 1.0976611375808716, 'learning_rate': 2.368421052631579e-05, 'epoch': 6.33}\n",
                        "{'loss': 0.3602, 'grad_norm': 1.086432933807373, 'learning_rate': 2.3391812865497074e-05, 'epoch': 6.38}\n",
                        "{'loss': 0.3616, 'grad_norm': 0.938676118850708, 'learning_rate': 2.309941520467836e-05, 'epoch': 6.43}\n",
                        "{'loss': 0.3381, 'grad_norm': 1.2526150941848755, 'learning_rate': 2.280701754385965e-05, 'epoch': 6.47}\n",
                        "{'loss': 0.3542, 'grad_norm': 0.8903213143348694, 'learning_rate': 2.2514619883040936e-05, 'epoch': 6.52}\n",
                        "{'loss': 0.3702, 'grad_norm': 1.4603773355484009, 'learning_rate': 2.2222222222222223e-05, 'epoch': 6.56}\n",
                        "{'loss': 0.3312, 'grad_norm': 0.9108341336250305, 'learning_rate': 2.1929824561403507e-05, 'epoch': 6.61}\n",
                        "{'loss': 0.3384, 'grad_norm': 0.9287604689598083, 'learning_rate': 2.1637426900584794e-05, 'epoch': 6.65}\n",
                        "{'loss': 0.344, 'grad_norm': 1.3636784553527832, 'learning_rate': 2.134502923976608e-05, 'epoch': 6.7}\n",
                        "{'loss': 0.3369, 'grad_norm': 0.9728419780731201, 'learning_rate': 2.105263157894737e-05, 'epoch': 6.74}\n",
                        "{'loss': 0.3438, 'grad_norm': 1.2640284299850464, 'learning_rate': 2.0760233918128656e-05, 'epoch': 6.79}\n",
                        "{'loss': 0.3565, 'grad_norm': 2.095876693725586, 'learning_rate': 2.046783625730994e-05, 'epoch': 6.83}\n",
                        "{'loss': 0.341, 'grad_norm': 1.551594614982605, 'learning_rate': 2.0175438596491227e-05, 'epoch': 6.88}\n",
                        "{'loss': 0.3441, 'grad_norm': 1.3781603574752808, 'learning_rate': 1.9883040935672515e-05, 'epoch': 6.92}\n",
                        "{'loss': 0.352, 'grad_norm': 1.1450177431106567, 'learning_rate': 1.9590643274853802e-05, 'epoch': 6.97}\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "7ca83443c3164352a399fb08dad9b468",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/79 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "{'eval_loss': 0.42528095841407776, 'eval_accuracy': 0.813448378458792, 'eval_runtime': 25.1401, 'eval_samples_per_second': 802.145, 'eval_steps_per_second': 3.142, 'epoch': 7.0}\n",
                        "{'loss': 0.3832, 'grad_norm': 1.7406375408172607, 'learning_rate': 1.929824561403509e-05, 'epoch': 7.01}\n",
                        "{'loss': 0.3532, 'grad_norm': 1.1327779293060303, 'learning_rate': 1.9005847953216373e-05, 'epoch': 7.06}\n",
                        "{'loss': 0.3366, 'grad_norm': 1.0839874744415283, 'learning_rate': 1.871345029239766e-05, 'epoch': 7.1}\n",
                        "{'loss': 0.3697, 'grad_norm': 1.6586799621582031, 'learning_rate': 1.8421052631578947e-05, 'epoch': 7.15}\n",
                        "{'loss': 0.3421, 'grad_norm': 1.015320897102356, 'learning_rate': 1.8128654970760235e-05, 'epoch': 7.19}\n",
                        "{'loss': 0.3628, 'grad_norm': 1.2317531108856201, 'learning_rate': 1.7836257309941522e-05, 'epoch': 7.24}\n",
                        "{'loss': 0.3627, 'grad_norm': 1.5394704341888428, 'learning_rate': 1.7543859649122806e-05, 'epoch': 7.29}\n",
                        "{'loss': 0.3544, 'grad_norm': 0.8848616480827332, 'learning_rate': 1.7251461988304093e-05, 'epoch': 7.33}\n",
                        "{'loss': 0.3626, 'grad_norm': 0.884719967842102, 'learning_rate': 1.695906432748538e-05, 'epoch': 7.38}\n",
                        "{'loss': 0.365, 'grad_norm': 1.22878098487854, 'learning_rate': 1.6666666666666667e-05, 'epoch': 7.42}\n",
                        "{'loss': 0.3307, 'grad_norm': 0.8882404565811157, 'learning_rate': 1.6374269005847955e-05, 'epoch': 7.47}\n",
                        "{'loss': 0.3452, 'grad_norm': 0.9432515501976013, 'learning_rate': 1.608187134502924e-05, 'epoch': 7.51}\n",
                        "{'loss': 0.3434, 'grad_norm': 1.0676875114440918, 'learning_rate': 1.5789473684210526e-05, 'epoch': 7.56}\n",
                        "{'loss': 0.3553, 'grad_norm': 1.0911734104156494, 'learning_rate': 1.5497076023391813e-05, 'epoch': 7.6}\n",
                        "{'loss': 0.3619, 'grad_norm': 0.9431406259536743, 'learning_rate': 1.5204678362573099e-05, 'epoch': 7.65}\n",
                        "{'loss': 0.3561, 'grad_norm': 1.077249526977539, 'learning_rate': 1.4912280701754386e-05, 'epoch': 7.69}\n",
                        "{'loss': 0.3519, 'grad_norm': 1.0270676612854004, 'learning_rate': 1.4619883040935673e-05, 'epoch': 7.74}\n",
                        "{'loss': 0.3509, 'grad_norm': 0.7694218158721924, 'learning_rate': 1.4327485380116959e-05, 'epoch': 7.78}\n",
                        "{'loss': 0.3413, 'grad_norm': 1.0720213651657104, 'learning_rate': 1.4035087719298246e-05, 'epoch': 7.83}\n",
                        "{'loss': 0.3587, 'grad_norm': 1.5637993812561035, 'learning_rate': 1.3742690058479531e-05, 'epoch': 7.87}\n",
                        "{'loss': 0.3368, 'grad_norm': 0.9845683574676514, 'learning_rate': 1.3450292397660819e-05, 'epoch': 7.92}\n",
                        "{'loss': 0.3586, 'grad_norm': 1.0955688953399658, 'learning_rate': 1.3157894736842106e-05, 'epoch': 7.96}\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "08ab133f9445445cb6b17d871b9708ae",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/79 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "{'eval_loss': 0.40961503982543945, 'eval_accuracy': 0.8202419914707925, 'eval_runtime': 25.3515, 'eval_samples_per_second': 795.457, 'eval_steps_per_second': 3.116, 'epoch': 8.0}\n",
                        "{'loss': 0.3542, 'grad_norm': 1.1746166944503784, 'learning_rate': 1.2865497076023392e-05, 'epoch': 8.01}\n",
                        "{'loss': 0.352, 'grad_norm': 1.1073132753372192, 'learning_rate': 1.2573099415204679e-05, 'epoch': 8.05}\n",
                        "{'loss': 0.338, 'grad_norm': 0.9531964063644409, 'learning_rate': 1.2280701754385964e-05, 'epoch': 8.1}\n",
                        "{'loss': 0.375, 'grad_norm': 1.139713168144226, 'learning_rate': 1.1988304093567252e-05, 'epoch': 8.14}\n",
                        "{'loss': 0.3465, 'grad_norm': 1.0720798969268799, 'learning_rate': 1.1695906432748537e-05, 'epoch': 8.19}\n",
                        "{'loss': 0.3342, 'grad_norm': 1.094533085823059, 'learning_rate': 1.1403508771929824e-05, 'epoch': 8.24}\n",
                        "{'loss': 0.3631, 'grad_norm': 1.5714579820632935, 'learning_rate': 1.1111111111111112e-05, 'epoch': 8.28}\n",
                        "{'loss': 0.3298, 'grad_norm': 0.8268879055976868, 'learning_rate': 1.0818713450292397e-05, 'epoch': 8.33}\n",
                        "{'loss': 0.3466, 'grad_norm': 1.0099811553955078, 'learning_rate': 1.0526315789473684e-05, 'epoch': 8.37}\n",
                        "{'loss': 0.3487, 'grad_norm': 1.146409511566162, 'learning_rate': 1.023391812865497e-05, 'epoch': 8.42}\n",
                        "{'loss': 0.3472, 'grad_norm': 1.3261864185333252, 'learning_rate': 9.941520467836257e-06, 'epoch': 8.46}\n",
                        "{'loss': 0.3303, 'grad_norm': 1.1992161273956299, 'learning_rate': 9.649122807017545e-06, 'epoch': 8.51}\n",
                        "{'loss': 0.3291, 'grad_norm': 0.8921419382095337, 'learning_rate': 9.35672514619883e-06, 'epoch': 8.55}\n",
                        "{'loss': 0.3528, 'grad_norm': 0.874587893486023, 'learning_rate': 9.064327485380117e-06, 'epoch': 8.6}\n",
                        "{'loss': 0.3374, 'grad_norm': 1.2230889797210693, 'learning_rate': 8.771929824561403e-06, 'epoch': 8.64}\n",
                        "{'loss': 0.3414, 'grad_norm': 0.8661026358604431, 'learning_rate': 8.47953216374269e-06, 'epoch': 8.69}\n",
                        "{'loss': 0.345, 'grad_norm': 0.9893231391906738, 'learning_rate': 8.187134502923977e-06, 'epoch': 8.73}\n",
                        "{'loss': 0.334, 'grad_norm': 0.9381342530250549, 'learning_rate': 7.894736842105263e-06, 'epoch': 8.78}\n",
                        "{'loss': 0.3622, 'grad_norm': 0.8007356524467468, 'learning_rate': 7.602339181286549e-06, 'epoch': 8.82}\n",
                        "{'loss': 0.3529, 'grad_norm': 1.1932841539382935, 'learning_rate': 7.3099415204678366e-06, 'epoch': 8.87}\n",
                        "{'loss': 0.3336, 'grad_norm': 0.9332574009895325, 'learning_rate': 7.017543859649123e-06, 'epoch': 8.91}\n",
                        "{'loss': 0.3587, 'grad_norm': 0.9339568018913269, 'learning_rate': 6.725146198830409e-06, 'epoch': 8.96}\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "6a51c10f9d9247399bf85a8b3d51750e",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/79 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "{'eval_loss': 0.4265603721141815, 'eval_accuracy': 0.8138450857879599, 'eval_runtime': 25.0909, 'eval_samples_per_second': 803.718, 'eval_steps_per_second': 3.149, 'epoch': 9.0}\n",
                        "{'loss': 0.3393, 'grad_norm': 1.524579405784607, 'learning_rate': 6.432748538011696e-06, 'epoch': 9.0}\n",
                        "{'loss': 0.3541, 'grad_norm': 1.1281825304031372, 'learning_rate': 6.140350877192982e-06, 'epoch': 9.05}\n",
                        "{'loss': 0.3492, 'grad_norm': 0.9135451316833496, 'learning_rate': 5.8479532163742686e-06, 'epoch': 9.1}\n",
                        "{'loss': 0.3435, 'grad_norm': 1.3494091033935547, 'learning_rate': 5.555555555555556e-06, 'epoch': 9.14}\n",
                        "{'loss': 0.3589, 'grad_norm': 0.952190637588501, 'learning_rate': 5.263157894736842e-06, 'epoch': 9.19}\n",
                        "{'loss': 0.3524, 'grad_norm': 1.0929826498031616, 'learning_rate': 4.970760233918129e-06, 'epoch': 9.23}\n",
                        "{'loss': 0.3371, 'grad_norm': 1.3541598320007324, 'learning_rate': 4.678362573099415e-06, 'epoch': 9.28}\n",
                        "{'loss': 0.3371, 'grad_norm': 0.9167181253433228, 'learning_rate': 4.3859649122807014e-06, 'epoch': 9.32}\n",
                        "{'loss': 0.335, 'grad_norm': 0.8863683342933655, 'learning_rate': 4.093567251461989e-06, 'epoch': 9.37}\n",
                        "{'loss': 0.3428, 'grad_norm': 1.0024056434631348, 'learning_rate': 3.8011695906432747e-06, 'epoch': 9.41}\n",
                        "{'loss': 0.3511, 'grad_norm': 1.6810412406921387, 'learning_rate': 3.5087719298245615e-06, 'epoch': 9.46}\n",
                        "{'loss': 0.3591, 'grad_norm': 1.0786285400390625, 'learning_rate': 3.216374269005848e-06, 'epoch': 9.5}\n",
                        "{'loss': 0.3319, 'grad_norm': 0.9200969934463501, 'learning_rate': 2.9239766081871343e-06, 'epoch': 9.55}\n",
                        "{'loss': 0.3439, 'grad_norm': 1.0153361558914185, 'learning_rate': 2.631578947368421e-06, 'epoch': 9.59}\n",
                        "{'loss': 0.3524, 'grad_norm': 0.951949417591095, 'learning_rate': 2.3391812865497075e-06, 'epoch': 9.64}\n",
                        "{'loss': 0.3478, 'grad_norm': 1.3876007795333862, 'learning_rate': 2.0467836257309943e-06, 'epoch': 9.68}\n",
                        "{'loss': 0.3469, 'grad_norm': 1.0073338747024536, 'learning_rate': 1.7543859649122807e-06, 'epoch': 9.73}\n",
                        "{'loss': 0.357, 'grad_norm': 1.3802759647369385, 'learning_rate': 1.4619883040935671e-06, 'epoch': 9.77}\n",
                        "{'loss': 0.3562, 'grad_norm': 1.92709219455719, 'learning_rate': 1.1695906432748538e-06, 'epoch': 9.82}\n",
                        "{'loss': 0.3373, 'grad_norm': 1.0409867763519287, 'learning_rate': 8.771929824561404e-07, 'epoch': 9.86}\n",
                        "{'loss': 0.3627, 'grad_norm': 0.9347881078720093, 'learning_rate': 5.847953216374269e-07, 'epoch': 9.91}\n",
                        "{'loss': 0.3373, 'grad_norm': 0.9216035008430481, 'learning_rate': 2.9239766081871344e-07, 'epoch': 9.95}\n",
                        "{'loss': 0.3412, 'grad_norm': 1.2602601051330566, 'learning_rate': 0.0, 'epoch': 10.0}\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "955bc4efbe2e49fe849aeb96030613a2",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/79 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "{'eval_loss': 0.4146804213523865, 'eval_accuracy': 0.8206386987999603, 'eval_runtime': 25.2269, 'eval_samples_per_second': 799.386, 'eval_steps_per_second': 3.132, 'epoch': 10.0}\n",
                        "{'train_runtime': 1111.2356, 'train_samples_per_second': 508.164, 'train_steps_per_second': 1.989, 'train_loss': 0.38526441144727475, 'epoch': 10.0}\n"
                    ]
                }
            ],
            "source": [
                "graph_prompter_hf_bert_classifier.train_model_on_data(\n",
                "    dataset_embedding,\n",
                "    epochs=EPOCHS,\n",
                "    batch_size=BATCH_SIZE_LLM,\n",
                ")\n",
                "# graph_representation_generator_graph_prompter_hf.save_model()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "True\n"
                    ]
                }
            ],
            "source": [
                "import torch\n",
                "\n",
                "tens_1 = graph_representation_generator_graph_prompter_hf.model.to(\n",
                "    device=\"cpu\"\n",
                ").state_dict()\n",
                "\n",
                "tens_2 = torch.load(\"./data/gnn/backup/model_128.pth\")\n",
                "same = True\n",
                "for key in tens_1.keys():\n",
                "    if isinstance(tens_1[key], torch.Tensor):\n",
                "        if not (tens_1[key] == tens_2[key]).all():\n",
                "            same = False\n",
                "print(same)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "hauptprojekt",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.4"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
