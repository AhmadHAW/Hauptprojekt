{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset_manager.movie_lens_manager import (\n",
    "    MovieLensManager,\n",
    "    ROOT,\n",
    ")\n",
    "from llm_manager.vanilla.classifier import VanillaClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "kg_manager = MovieLensManager()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "VANILLA_ROOT = f\"{ROOT}/llm/vanilla\"\n",
    "GRAPH_PROMPTER_HF_FROZEN_ROOT = f\"{ROOT}/llm/graph_prompter_hf_frozen\"\n",
    "GRAPH_PROMPTER_HF_ROOT = f\"{ROOT}/llm/graph_prompter_hf\"\n",
    "MODEL_NAME = \"google/bert_uncased_L-2_H-128_A-2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device cuda\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "vanilla_bert_classifier = VanillaClassifier(\n",
    "    kg_manager.llm_df,\n",
    "    kg_manager.source_df,\n",
    "    kg_manager.target_df,\n",
    "    root_path=VANILLA_ROOT,\n",
    "    model_name=MODEL_NAME,\n",
    "    false_ratio=-1,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_vanilla = kg_manager.generate_vanilla_dataset(\n",
    "    vanilla_bert_classifier.tokenize_function, suffix=\"_shard_1000000\"\n",
    ")\n",
    "dataset_embedding = kg_manager.generate_graph_prompter_hf_embedding_dataset(\n",
    "    \"[SEP]\", \"[PAD]\", suffix=\"_shard_1000000\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dataset_vanilla = kg_manager.generate_vanilla_dataset()\n",
    "dataset_graph_prompter_hf = kg_manager.generate_graph_prompter_hf_embedding_dataset(\n",
    "    \"[SEP]\", \"[PAD]\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19d31d19515a40388831af7953e12cdd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/116365 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5489eb4dada4ee0bbac8d7fbf25a2c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/116365 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b8fc78842744c6d8c69abbdbbe0e05f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/116365 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc4f4443ecc84d6b8c473fbb469d351e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/116365 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f73092aafde742688c3ec16375056c4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/116365 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77d35b6eb0d447e7842af28e368bd790",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/116365 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset_vanilla, _ = kg_manager.shard_dataset_randomly(\n",
    "    VANILLA_ROOT,\n",
    "    GRAPH_PROMPTER_HF_FROZEN_ROOT,\n",
    "    GRAPH_PROMPTER_HF_ROOT,\n",
    "    vanilla_dataset=dataset_vanilla,\n",
    "    graph_prompter_hf_dataset=dataset_embedding,\n",
    "    shard_size=100000,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    test: Dataset({\n",
       "        features: ['source_id', 'target_id', 'split', 'labels', 'prompt_feature_title', 'prompt_feature_genres', 'prompt', 'input_ids', 'attention_mask', 'token_type_ids'],\n",
       "        num_rows: 116365\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['source_id', 'target_id', 'split', 'labels', 'prompt_feature_title', 'prompt_feature_genres', 'prompt', 'input_ids', 'attention_mask', 'token_type_ids'],\n",
       "        num_rows: 116365\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_vanilla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split test\n",
      "forwarding without masking ./data/llm/vanilla/attentions/split_test_pos_0_com_[].npy\n",
      "combination: frozenset()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BertSdpaSelfAttention is used but `torch.nn.functional.scaled_dot_product_attention` does not support non-absolute `position_embedding_type` or `output_attentions=True` or `head_mask`. Falling back to the manual attention implementation, but specifying the manual implementation will be required from Transformers version v5.0.0 onwards. This warning can be removed using the argument `attn_implementation=\"eager\"` when loading the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "combination: frozenset({0})\n",
      "combination: frozenset({1})\n",
      "combination: frozenset({2})\n",
      "combination: frozenset({3})\n",
      "combination: frozenset({0, 1})\n",
      "combination: frozenset({0, 2})\n",
      "combination: frozenset({0, 3})\n",
      "combination: frozenset({1, 2})\n",
      "combination: frozenset({1, 3})\n",
      "combination: frozenset({2, 3})\n",
      "combination: frozenset({0, 1, 2})\n",
      "combination: frozenset({0, 1, 3})\n",
      "combination: frozenset({0, 2, 3})\n",
      "combination: frozenset({1, 2, 3})\n",
      "combination: frozenset({0, 1, 2, 3})\n",
      "split val\n",
      "forwarding without masking ./data/llm/vanilla/attentions/split_val_pos_0_com_[].npy\n",
      "combination: frozenset()\n",
      "combination: frozenset({0})\n",
      "combination: frozenset({1})\n",
      "combination: frozenset({2})\n",
      "combination: frozenset({3})\n",
      "combination: frozenset({0, 1})\n",
      "combination: frozenset({0, 2})\n",
      "combination: frozenset({0, 3})\n",
      "combination: frozenset({1, 2})\n",
      "combination: frozenset({1, 3})\n",
      "combination: frozenset({2, 3})\n",
      "combination: frozenset({0, 1, 2})\n",
      "combination: frozenset({0, 1, 3})\n",
      "combination: frozenset({0, 2, 3})\n",
      "combination: frozenset({1, 2, 3})\n",
      "combination: frozenset({0, 1, 2, 3})\n"
     ]
    }
   ],
   "source": [
    "vanilla_bert_classifier.forward_dataset_and_save_outputs(\n",
    "    dataset=dataset_vanilla,\n",
    "    batch_size=1024,\n",
    "    save_step_size=1250,\n",
    "    splits=[\"test\", \"val\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hauptprojekt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
