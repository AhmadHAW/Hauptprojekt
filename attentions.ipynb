{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertConfig\n",
    "from gnn import GNNTrainer\n",
    "from movie_lens_loader import MovieLensLoader\n",
    "from llm import PromptBertClassifier, VanillaBertClassifier, AddingEmbeddingsBertClassifierBase,mean_over_ranges, avg_over_states\n",
    "\n",
    "import itertools\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import networkx as nx\n",
    "import os\n",
    "import pandas as pd\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = BertConfig.from_pretrained(\"google/bert_uncased_L-2_H-128_A-2\")\n",
    "KGE_DIMENSION_PROMPT = 4\n",
    "KGE_DIMENSION_ADDING = 128\n",
    "KGE_DIMENSIONS = [KGE_DIMENSION_PROMPT, KGE_DIMENSION_ADDING] # Output Dimension of the GNN Encoder.\n",
    "model_max_length = 256\n",
    "movie_lens_loader = MovieLensLoader(kge_dimensions = KGE_DIMENSIONS)\n",
    "gnn_trainer_prompt =    GNNTrainer(movie_lens_loader.data, kge_dimension = KGE_DIMENSION_PROMPT)\n",
    "gnn_trainer_prompt.get_embeddings(movie_lens_loader)\n",
    "gnn_trainer_adding =    GNNTrainer(movie_lens_loader.data, hidden_channels=KGE_DIMENSION_ADDING, kge_dimension = KGE_DIMENSION_ADDING)\n",
    "gnn_trainer_adding.get_embeddings(movie_lens_loader)\n",
    "vanilla_bert_only_classifier = VanillaBertClassifier(movie_lens_loader.llm_df,model_max_length = model_max_length)\n",
    "dataset_vanilla = movie_lens_loader.generate_vanilla_dataset(vanilla_bert_only_classifier.tokenize_function)\n",
    "prompt_bert_only_classifier = PromptBertClassifier(movie_lens_loader, gnn_trainer_prompt.get_embedding, kge_dimension=gnn_trainer_prompt.kge_dimension, batch_size=64,model_max_length = model_max_length)\n",
    "dataset_prompt = movie_lens_loader.generate_prompt_embedding_dataset(prompt_bert_only_classifier.tokenize_function, kge_dimension = prompt_bert_only_classifier.kge_dimension)\n",
    "adding_embedding_bert_only_classifier = AddingEmbeddingsBertClassifierBase(movie_lens_loader, gnn_trainer_adding.get_embedding, kge_dimension=config.hidden_size, batch_size=64,model_max_length = model_max_length)\n",
    "dataset_adding_embedding = movie_lens_loader.generate_adding_embedding_dataset(adding_embedding_bert_only_classifier.tokenizer.sep_token, adding_embedding_bert_only_classifier.tokenizer.pad_token, adding_embedding_bert_only_classifier.tokenize_function, kge_dimension = config.hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_lens_loader.llm_df[\"user_embedding_4\"][movie_lens_loader.llm_df[\"user_embedding_4\"].apply(lambda emb: \"e\"  in emb)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_lens_loader.llm_df[\"user_embedding_4\"].apply(lambda ebs: ast.literal_eval(ebs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vanilla_hidden_states, vanilla_attentions = vanilla_bert_only_classifier.forward_dataset_and_save_outputs(dataset_vanilla)\n",
    "prompt_hidden_states, prompt_attentions = prompt_bert_only_classifier.forward_dataset_and_save_outputs(dataset_prompt)\n",
    "adding_embedding_hidden_states, adding_embedding_attentions = adding_embedding_bert_only_classifier.forward_dataset_and_save_outputs(dataset_adding_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tokens_as_df_vanilla(self: VanillaBertClassifier, input_ids, all_ranges_over_batch) -> pd.DataFrame:\n",
    "    user_ids = []\n",
    "    titles = []\n",
    "    genres = []\n",
    "    all_semantic_tokens = [user_ids, titles, genres]\n",
    "    ends = all_ranges_over_batch[:,:,1]\n",
    "    starts = all_ranges_over_batch[:,:,0]\n",
    "    # input: # ends: torch.tensor([2, 5, 6]) starts: tensor([0, 2, 4])\n",
    "    # Compute the maximum length of the ranges\n",
    "    max_length = (ends - starts).max()\n",
    "    # Create a range tensor from 0 to max_length-1\n",
    "    range_tensor = torch.arange(max_length).unsqueeze(0)\n",
    "    for pos, semantic_tokens in enumerate(all_semantic_tokens):\n",
    "        # Compute the ranges using broadcasting and masking\n",
    "        ranges =  starts[:,pos].unsqueeze(1) + range_tensor\n",
    "        mask = ranges < ends[:,pos].unsqueeze(1)\n",
    "\n",
    "        # Apply the mask\n",
    "        result = ranges * mask  # result: tensor([[0, 1, 0], [2, 3, 4], [4, 5, 0]]) here padding index is 0\n",
    "                                #                        -                     -    positions were padded\n",
    "        #result = result.unsqueeze(dim = 2).repeat(1,1, input_ids.shape[2])\n",
    "        gather = input_ids.gather(dim = 1, index = result)\n",
    "        decoded = self.tokenizer.batch_decode(gather, skip_special_tokens = True)\n",
    "        if pos == 0:\n",
    "            semantic_tokens.extend([decode[len(\"user : \"):] for decode in decoded])\n",
    "        if pos == 1:\n",
    "            semantic_tokens.extend([decode[len(\"title : \"):] for decode in decoded])\n",
    "        if pos == 2:\n",
    "            semantic_tokens.extend([decode[len(\"genres : \"):] for decode in decoded])\n",
    "    all_semantic_tokens[0] = [int(id) for id in all_semantic_tokens[0]]\n",
    "    all_semantic_tokens[2] = [ast.literal_eval(string_list) for string_list in all_semantic_tokens[2]]\n",
    "    data = {\"user_id\": all_semantic_tokens[0], \"title\": all_semantic_tokens[1], \"genres\": all_semantic_tokens[2]}\n",
    "    df = pd.DataFrame(data)\n",
    "    return df\n",
    "\n",
    "def get_tokens_as_df_prompt(self: PromptBertClassifier, input_ids, all_ranges_over_batch) -> pd.DataFrame:\n",
    "    user_ids = []\n",
    "    titles = []\n",
    "    genres = []\n",
    "    user_embeddings = []\n",
    "    movie_embeddings = []\n",
    "    all_semantic_tokens = [user_ids, titles, genres, user_embeddings, movie_embeddings]\n",
    "    ends = all_ranges_over_batch[:,:,1]\n",
    "    starts = all_ranges_over_batch[:,:,0]\n",
    "    # input: # ends: torch.tensor([2, 5, 6]) starts: tensor([0, 2, 4])\n",
    "    # Compute the maximum length of the ranges\n",
    "    max_length = (ends - starts).max()\n",
    "    # Create a range tensor from 0 to max_length-1\n",
    "    range_tensor = torch.arange(max_length).unsqueeze(0)\n",
    "    for pos, semantic_tokens in enumerate(all_semantic_tokens):\n",
    "        # Compute the ranges using broadcasting and masking\n",
    "        ranges =  starts[:,pos].unsqueeze(1) + range_tensor\n",
    "        mask = ranges < ends[:,pos].unsqueeze(1)\n",
    "\n",
    "        # Apply the mask\n",
    "        result = ranges * mask  # result: tensor([[0, 1, 0], [2, 3, 4], [4, 5, 0]]) here padding index is 0\n",
    "                                #                        -                     -    positions were padded\n",
    "        #result = result.unsqueeze(dim = 2).repeat(1,1, input_ids.shape[2])\n",
    "        gather = input_ids.gather(dim = 1, index = result)\n",
    "        decoded = self.tokenizer.batch_decode(gather, skip_special_tokens = True)\n",
    "        if pos == 0:\n",
    "            semantic_tokens.extend([decode[len(\"user : \"):] for decode in decoded])\n",
    "        if pos == 1:\n",
    "            semantic_tokens.extend([decode[len(\"title : \"):] for decode in decoded])\n",
    "        if pos == 2:\n",
    "            semantic_tokens.extend([decode[len(\"genres : \"):] for decode in decoded])\n",
    "        if pos == 3:\n",
    "            semantic_tokens.extend([decode[len(\"user_embeddings :\"):] for decode in decoded])\n",
    "        if pos == 4:\n",
    "            semantic_tokens.extend([decode[len(\"movie_embeddings :\"):] for decode in decoded])\n",
    "    all_semantic_tokens[0] = [int(id) for id in all_semantic_tokens[0]]\n",
    "    all_semantic_tokens[2] = [ast.literal_eval(string_list) for string_list in all_semantic_tokens[2]]\n",
    "    all_semantic_tokens[3] = [ast.literal_eval(string_list.replace(\" \", \"\")) for string_list in all_semantic_tokens[3]]\n",
    "    all_semantic_tokens[4] = [ast.literal_eval(string_list.replace(\" \", \"\")) for string_list in all_semantic_tokens[4]]\n",
    "    user_embeddings = torch.tensor(all_semantic_tokens[3])\n",
    "    movie_embeddings = torch.tensor(all_semantic_tokens[4])\n",
    "    graph_embeddings = torch.stack([user_embeddings, movie_embeddings])\n",
    "    data = {\"user_id\": all_semantic_tokens[0], \"title\": all_semantic_tokens[1], \"genres\": all_semantic_tokens[2], \"user_embeddings\": all_semantic_tokens[3], \"movie_embeddings\": all_semantic_tokens[4]}\n",
    "    df = pd.DataFrame(data)\n",
    "    return df, graph_embeddings\n",
    "\n",
    "def forward_dataset_and_save_outputs(self: VanillaBertClassifier, dataset, splits = [\"val\"], batch_size = 64, epochs = 3, force_recompute = False):\n",
    "    if force_recompute or not os.path.exists(self.attentions_path) or not os.path.exists(self.hidden_states_path) or not os.path.exists(self.tokens_path):\n",
    "        self.model.eval()\n",
    "        last_hidden_states = []\n",
    "        all_attentions = []\n",
    "        all_ranges_over_batch = []\n",
    "        input_ids =  []\n",
    "        labels = []\n",
    "        splits_ = []\n",
    "        for split in splits:\n",
    "            splits_.extend([split] * epochs * batch_size) #* len(dataset[split]))\n",
    "            data_collator = self._get_data_collator(split)\n",
    "            for epoch in range(epochs):\n",
    "                data_loader = DataLoader(dataset=dataset[split], batch_size= batch_size, collate_fn = data_collator)\n",
    "                #for idx, batch in enumerate(data_loader):\n",
    "                if True:\n",
    "                    batch = next(iter(data_loader))\n",
    "                    with torch.no_grad():\n",
    "                        outputs = self.model(input_ids = batch[\"input_ids\"], attention_mask = batch[\"attention_mask\"], output_hidden_states=True, output_attentions = True)\n",
    "                        input_ids.append(batch[\"input_ids\"])\n",
    "                        labels.extend(batch[\"labels\"])\n",
    "                        hidden_states = outputs.hidden_states\n",
    "                        attentions = outputs.attentions\n",
    "                        last_hidden_states.append(hidden_states[-1])\n",
    "                        ranges_over_batch = self._get_ranges_over_batch(batch[\"input_ids\"])\n",
    "                        all_ranges_over_batch.append(ranges_over_batch)\n",
    "                        all_attentions.append(torch.stack([torch.sum(attention, dim=1).detach() for attention in attentions]))\n",
    "        # Concatenate all hidden states across batches\n",
    "        last_hidden_states = torch.cat(last_hidden_states)\n",
    "        all_ranges_over_batch = torch.cat(all_ranges_over_batch)\n",
    "        input_ids = torch.cat(input_ids)\n",
    "        labels = torch.stack(labels).tolist()\n",
    "        all_attentions = [layer.reshape(layer.shape[1], layer.shape[2], layer.shape[3], -1) for layer in all_attentions]\n",
    "        all_attentions = torch.cat(all_attentions)\n",
    "        averaged_hidden_states, averaged_attentions = avg_over_states(all_ranges_over_batch, last_hidden_states, all_attentions)\n",
    "        all_tokens = get_tokens_as_df_prompt(self, input_ids, all_ranges_over_batch)\n",
    "        all_tokens[\"labels\"] = labels\n",
    "        all_tokens[\"split\"] = splits_ \n",
    "        \n",
    "        torch.save(averaged_attentions, self.attentions_path)\n",
    "        torch.save(averaged_hidden_states, self.hidden_states_path)\n",
    "        all_tokens.to_csv(self.tokens_path, index = False)\n",
    "        #averaged_hidden_states =averaged_hidden_states.reshape(averaged_hidden_states.shape[1], averaged_hidden_states.shape[0], -1)\n",
    "    else:\n",
    "        averaged_hidden_states = torch.load(self.hidden_states_path)\n",
    "        averaged_attentions = torch.load(self.attentions_path)\n",
    "        all_tokens = pd.read_csv(self.tokens_path)\n",
    "    return averaged_hidden_states, averaged_attentions, all_tokens\n",
    "\n",
    "def forward_dataset_and_save_outputs_prompt(self: PromptBertClassifier, dataset, splits = [\"val\"], batch_size = 64, epochs = 3, force_recompute = False):\n",
    "    if force_recompute or not os.path.exists(self.attentions_path) or not os.path.exists(self.hidden_states_path) or not os.path.exists(self.tokens_path):\n",
    "        self.model.eval()\n",
    "        last_hidden_states = []\n",
    "        all_attentions = []\n",
    "        all_ranges_over_batch = []\n",
    "        input_ids =  []\n",
    "        labels = []\n",
    "        splits_ = []\n",
    "        for split in splits:\n",
    "            splits_.extend([split] * epochs * batch_size) #* len(dataset[split]))\n",
    "            data_collator = self._get_data_collator(split)\n",
    "            for epoch in range(epochs):\n",
    "                data_loader = DataLoader(dataset=dataset[split], batch_size= batch_size, collate_fn = data_collator)\n",
    "                #for idx, batch in enumerate(data_loader):\n",
    "                if True:\n",
    "                    batch = next(iter(data_loader))\n",
    "                    with torch.no_grad():\n",
    "                        outputs = self.model(input_ids = batch[\"input_ids\"], attention_mask = batch[\"attention_mask\"], output_hidden_states=True, output_attentions = True)\n",
    "                        input_ids.append(batch[\"input_ids\"])\n",
    "                        labels.extend(batch[\"labels\"])\n",
    "                        hidden_states = outputs.hidden_states\n",
    "                        attentions = outputs.attentions\n",
    "                        last_hidden_states.append(hidden_states[-1])\n",
    "                        ranges_over_batch = self._get_ranges_over_batch(batch[\"input_ids\"])\n",
    "                        all_ranges_over_batch.append(ranges_over_batch)\n",
    "                        all_attentions.append(torch.stack([torch.sum(attention, dim=1).detach() for attention in attentions]))\n",
    "        # Concatenate all hidden states across batches\n",
    "        last_hidden_states = torch.cat(last_hidden_states)\n",
    "        all_ranges_over_batch = torch.cat(all_ranges_over_batch)\n",
    "        input_ids = torch.cat(input_ids)\n",
    "        labels = torch.stack(labels).tolist()\n",
    "        all_attentions = [layer.reshape(layer.shape[1], layer.shape[2], layer.shape[3], -1) for layer in all_attentions]\n",
    "        all_attentions = torch.cat(all_attentions)\n",
    "        averaged_hidden_states, averaged_attentions = avg_over_states(all_ranges_over_batch, last_hidden_states, all_attentions)\n",
    "        all_tokens, graph_embeddings = get_tokens_as_df_prompt(self, input_ids, all_ranges_over_batch)\n",
    "        all_tokens[\"labels\"] = labels\n",
    "        all_tokens[\"split\"] = splits_ \n",
    "        \n",
    "        torch.save(averaged_attentions, self.attentions_path)\n",
    "        torch.save(averaged_hidden_states, self.hidden_states_path)\n",
    "        torch.save(graph_embeddings, self.graph_embeddings_path)\n",
    "        all_tokens.to_csv(self.tokens_path, index = False)\n",
    "        #averaged_hidden_states =averaged_hidden_states.reshape(averaged_hidden_states.shape[1], averaged_hidden_states.shape[0], -1)\n",
    "    else:\n",
    "        averaged_hidden_states = torch.load(self.hidden_states_path)\n",
    "        averaged_attentions = torch.load(self.attentions_path)\n",
    "        graph_embeddings = torch.load(self.graph_embeddings)\n",
    "        all_tokens = pd.read_csv(self.tokens_path)\n",
    "    return averaged_hidden_states, averaged_attentions, graph_embeddings, all_tokens\n",
    "\n",
    "\n",
    "def forward_dataset_and_save_outputs_adding(self: AddingEmbeddingsBertClassifierBase, dataset, splits = [\"val\"], batch_size = 64, epochs = 3, force_recompute = False):\n",
    "    if force_recompute or not os.path.exists(self.attentions_path) or not os.path.exists(self.hidden_states_path) or not os.path.exists(self.tokens_path):\n",
    "        self.model.eval()\n",
    "        last_hidden_states = []\n",
    "        all_attentions = []\n",
    "        all_ranges_over_batch = []\n",
    "        input_ids =  []\n",
    "        labels = []\n",
    "        graph_embeddings = []\n",
    "        splits_ = []\n",
    "        for split in splits:\n",
    "            splits_.extend([split] * epochs * batch_size) #* len(dataset[split]))\n",
    "            data_collator = self._get_data_collator(split)\n",
    "            for epoch in range(epochs):\n",
    "                data_loader = DataLoader(dataset=dataset[split], batch_size= batch_size, collate_fn = data_collator)\n",
    "                #for idx, batch in enumerate(data_loader):\n",
    "                if True:\n",
    "                    batch = next(iter(data_loader))\n",
    "                    with torch.no_grad():\n",
    "                        outputs = self.model(input_ids = batch[\"input_ids\"], attention_mask = batch[\"attention_mask\"], graph_embeddings =  batch[\"graph_embeddings\"], output_hidden_states=True, output_attentions = True)\n",
    "                        input_ids.append(batch[\"input_ids\"])\n",
    "                        graph_embeddings.append(batch[\"graph_embeddings\"])\n",
    "                        labels.extend(batch[\"labels\"])\n",
    "                        hidden_states = outputs.hidden_states\n",
    "                        attentions = outputs.attentions\n",
    "                        last_hidden_states.append(hidden_states[-1])\n",
    "                        ranges_over_batch = self._get_ranges_over_batch(batch[\"input_ids\"])\n",
    "                        all_ranges_over_batch.append(ranges_over_batch)\n",
    "                        all_attentions.append(torch.stack([torch.sum(attention, dim=1).detach() for attention in attentions]))\n",
    "        # Concatenate all hidden states across batches\n",
    "        graph_embeddings = torch.cat(graph_embeddings)\n",
    "        last_hidden_states = torch.cat(last_hidden_states)\n",
    "        all_ranges_over_batch = torch.cat(all_ranges_over_batch)\n",
    "        input_ids = torch.cat(input_ids)\n",
    "        labels = torch.stack(labels).tolist()\n",
    "        all_attentions = [layer.reshape(layer.shape[1], layer.shape[2], layer.shape[3], -1) for layer in all_attentions]\n",
    "        all_attentions = torch.cat(all_attentions)\n",
    "        averaged_hidden_states, averaged_attentions = avg_over_states(all_ranges_over_batch, last_hidden_states, all_attentions)\n",
    "        all_tokens = get_tokens_as_df_vanilla(self, input_ids, all_ranges_over_batch)\n",
    "        all_tokens[\"labels\"] = labels\n",
    "        all_tokens[\"split\"] = splits_ \n",
    "        \n",
    "        torch.save(averaged_attentions, self.attentions_path)\n",
    "        torch.save(averaged_hidden_states, self.hidden_states_path)\n",
    "        torch.save(graph_embeddings, self.graph_embeddings_path)\n",
    "        all_tokens.to_csv(self.tokens_path, index = False)\n",
    "        #averaged_hidden_states =averaged_hidden_states.reshape(averaged_hidden_states.shape[1], averaged_hidden_states.shape[0], -1)\n",
    "    else:\n",
    "        averaged_hidden_states = torch.load(self.hidden_states_path)\n",
    "        averaged_attentions = torch.load(self.attentions_path)\n",
    "        graph_embeddings = torch.load(self.graph_embeddings)\n",
    "        all_tokens = pd.read_csv(self.tokens_path)\n",
    "    return averaged_hidden_states, averaged_attentions, graph_embeddings, all_tokens\n",
    "prompt_hidden_states, prompt_attentions, graph_embeddings, all_tokens = forward_dataset_and_save_outputs_prompt(prompt_bert_only_classifier, dataset_prompt, splits = [\"train\",\"test\", \"val\"], force_recompute=True)\n",
    "prompt_hidden_states.shape, prompt_attentions.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_prompt[\"train\"][\"prompt\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in dataset_prompt[\"test\"][\"prompt\"]:\n",
    "    if \"][SEP]movie embedding: \" not in row:\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vanilla_bert_only_classifier.plot_attention_graph(vanilla_attentions, \"Vanilla Attentions Grouped by relevant Semantic Ranges.\")\n",
    "prompt_bert_only_classifier.plot_attention_graph(prompt_attentions, \"Prompt Attentions Grouped by relevant Semantic Ranges.\")\n",
    "adding_embedding_bert_only_classifier.plot_attention_graph(adding_embedding_attentions, \"Embedding Attentions Grouped by relevant Semantic Ranges.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vanilla_bert_only_classifier.plot_attention_graph(vanilla_attention_matrix_normalized, \"Vanilla Attentions Grouped by relevant Semantic Ranges and Normalzied over Layers.\")\n",
    "prompt_bert_only_classifier.plot_attention_graph(prompt_attention_matrix_normalized, \"Prompt Attentions Grouped by relevant Semantic Ranges and Normalzied over Layers.\")\n",
    "adding_embedding_bert_only_classifier.plot_attention_graph(adding_embedding_attention_matrix_normalized, \"Embedding Attentions Grouped by relevant Semantic Ranges and Normalzied over Layers.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "grundprojekt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
