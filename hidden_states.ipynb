{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertConfig\n",
    "from gnn import GNNTrainer\n",
    "from movie_lens_loader import MovieLensLoader\n",
    "from llm import PromptBertClassifier, VanillaBertClassifier, AddingEmbeddingsBertClassifierBase, mean_over_ranges\n",
    "\n",
    "import itertools\n",
    "import random as rd\n",
    "from typing import List\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import networkx as nx\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = BertConfig.from_pretrained(\"google/bert_uncased_L-2_H-128_A-2\")\n",
    "KGE_DIMENSION_PROMPT = 4\n",
    "KGE_DIMENSION_ADDING = 128\n",
    "KGE_DIMENSIONS = [KGE_DIMENSION_PROMPT, KGE_DIMENSION_ADDING] # Output Dimension of the GNN Encoder.\n",
    "model_max_length = 256\n",
    "movie_lens_loader = MovieLensLoader(kge_dimensions = KGE_DIMENSIONS)\n",
    "gnn_trainer_prompt =    GNNTrainer(movie_lens_loader.data, kge_dimension = KGE_DIMENSION_PROMPT)\n",
    "gnn_trainer_prompt.get_embeddings(movie_lens_loader)\n",
    "gnn_trainer_adding =    GNNTrainer(movie_lens_loader.data, hidden_channels=KGE_DIMENSION_ADDING, kge_dimension = KGE_DIMENSION_ADDING)\n",
    "gnn_trainer_adding.get_embeddings(movie_lens_loader)\n",
    "vanilla_bert_only_classifier = VanillaBertClassifier(movie_lens_loader.llm_df,model_max_length = model_max_length)\n",
    "dataset_vanilla = movie_lens_loader.generate_vanilla_dataset(vanilla_bert_only_classifier.tokenize_function)\n",
    "prompt_bert_only_classifier = PromptBertClassifier(movie_lens_loader, gnn_trainer_prompt.get_embedding, kge_dimension=gnn_trainer_prompt.kge_dimension, batch_size=64,model_max_length = model_max_length)\n",
    "dataset_prompt = movie_lens_loader.generate_prompt_embedding_dataset(prompt_bert_only_classifier.tokenize_function, kge_dimension = prompt_bert_only_classifier.kge_dimension)\n",
    "adding_embedding_bert_only_classifier = AddingEmbeddingsBertClassifierBase(movie_lens_loader, gnn_trainer_adding.get_embedding, kge_dimension=config.hidden_size, batch_size=64,model_max_length = model_max_length)\n",
    "dataset_adding_embedding = movie_lens_loader.generate_adding_embedding_dataset(adding_embedding_bert_only_classifier.tokenizer.sep_token, adding_embedding_bert_only_classifier.tokenizer.pad_token, adding_embedding_bert_only_classifier.tokenize_function, kge_dimension = config.hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vanilla_hidden_states, vanilla_attentions = vanilla_bert_only_classifier.forward_dataset_and_save_outputs(dataset_vanilla)\n",
    "prompt_hidden_states, prompt_attentions = prompt_bert_only_classifier.forward_dataset_and_save_outputs(dataset_prompt)\n",
    "adding_embedding_hidden_states, adding_embedding_attentions = adding_embedding_bert_only_classifier.forward_dataset_and_save_outputs(dataset_adding_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_pca(self: VanillaBertClassifier, hidden_states, force_recompute = False):\n",
    "    if self.pcas_exists() and not force_recompute:\n",
    "        return self.load_pcas()\n",
    "    else:\n",
    "        \n",
    "        hidden_states = hidden_states.numpy()\n",
    "        pcas = []\n",
    "        for idx, label in enumerate(self.semantic_datapoints):\n",
    "            pca = PCA(n_components=2)  # Adjust number of components as needed\n",
    "            pcas.append(pca)\n",
    "            position_hidden_states = hidden_states[idx]\n",
    "            pca.fit_transform(position_hidden_states)\n",
    "            self.save_pca(pca, label = label)\n",
    "        return pcas\n",
    "vanilla_pcas = init_pca(vanilla_bert_only_classifier, vanilla_hidden_states, force_recompute = True)\n",
    "prompt_pcas = init_pca(prompt_bert_only_classifier, prompt_hidden_states, force_recompute = True)\n",
    "embedding_pcas = init_pca(adding_embedding_bert_only_classifier, adding_embedding_hidden_states, force_recompute = True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hidden_states_with_pca(vanilla_classifier, prompt_classifier, embedding_classifier, vanilla_pcas, prompt_pcas, embedding_pcas, prompt_getting_embedding_cb, embedding_getting_embedding_cb, n = 1, false_ratio = 0.7, plot_filters = ['vanilla user', 'vanilla title', 'vanilla genres', 'prompt user', 'prompt title', 'prompt genres', 'prompt user embedding', 'prompt movie embedding', 'embedding user', 'embedding title', 'embedding genres', 'embedding user embedding', 'embedding movie embedding'], singular_user = False, singular_title = False):\n",
    "    vanilla_classifier.model.eval()\n",
    "    prompt_classifier.model.eval()\n",
    "    embedding_classifier.model.eval()\n",
    "    samples = []\n",
    "    all_low_dim_reps_vanilla,all_low_dim_reps_prompt, all_low_dim_reps_embedding = [], [], []\n",
    "    for sample_num in range(n):\n",
    "        existing = rd.uniform(0, 1) >=( 1 / (false_ratio + 1))\n",
    "        sample_vanilla, sample_prompt, sample_embedding, random_row = movie_lens_loader.sample_datapoints(existing=existing, vanilla_classifier=vanilla_classifier, prompt_classifier=prompt_classifier, embedding_classifier=embedding_classifier, prompt_getting_embedding_cb = prompt_getting_embedding_cb, embedding_getting_embedding_cb = embedding_getting_embedding_cb, singular_user=singular_user, singular_title=singular_title)\n",
    "        samples.append(random_row)\n",
    "        with torch.no_grad():\n",
    "            outputs_vanilla = vanilla_classifier.forward_batch(sample_vanilla, output_hidden_states = True)\n",
    "            outputs_prompt = prompt_classifier.forward_batch(sample_prompt, output_hidden_states = True)\n",
    "            outputs_embedding = embedding_classifier.forward_batch(sample_embedding, output_hidden_states = True)\n",
    "            last_hidden_states_vanilla = outputs_vanilla.hidden_states[-1].squeeze()\n",
    "            last_hidden_states_prompt = outputs_prompt.hidden_states[-1].squeeze()\n",
    "            last_hidden_states_embedding = outputs_embedding.hidden_states[-1].squeeze()\n",
    "\n",
    "            ranges_vanilla = vanilla_classifier._get_ranges_over_batch(sample_vanilla[\"input_ids\"])[0]\n",
    "            range_last_hidden_states_vanilla = torch.zeros((len(ranges_vanilla),last_hidden_states_vanilla.shape[-1]))\n",
    "            for idx, range_borders in enumerate(ranges_vanilla):\n",
    "                range_ = torch.arange(range_borders[0], range_borders[1])\n",
    "                range_last_hidden_states_vanilla[idx] = torch.mean(last_hidden_states_vanilla[range_], dim=0)\n",
    "            # Convert to numpy arrays\n",
    "            range_last_hidden_states_vanilla = range_last_hidden_states_vanilla.detach().numpy()\n",
    "            low_dim_reps_vanilla = []\n",
    "            all_low_dim_reps_vanilla.append(low_dim_reps_vanilla)\n",
    "            for pca, last_hidden_state in zip(vanilla_pcas, last_hidden_states_vanilla):\n",
    "                low_dim_rep = pca.transform(last_hidden_state.unsqueeze(dim = 0))[0]\n",
    "                low_dim_reps_vanilla.append(low_dim_rep)\n",
    "\n",
    "            ranges_prompt = prompt_classifier._get_ranges_over_batch(sample_prompt[\"input_ids\"])[0]\n",
    "            range_last_hidden_states_prompt = torch.zeros((len(ranges_prompt),last_hidden_states_prompt.shape[-1]))\n",
    "            for idx, range_borders in enumerate(ranges_prompt):\n",
    "                range_ = torch.arange(range_borders[0], range_borders[1])\n",
    "                range_last_hidden_states_prompt[idx] = torch.mean(last_hidden_states_prompt[range_], dim=0)\n",
    "            # Convert to numpy arrays\n",
    "            range_last_hidden_states_prompt = range_last_hidden_states_prompt.detach().numpy()\n",
    "            low_dim_reps_prompt = []\n",
    "            all_low_dim_reps_prompt.append(low_dim_reps_prompt)\n",
    "            for pca, last_hidden_state in zip(prompt_pcas, last_hidden_states_prompt):\n",
    "                low_dim_rep = pca.transform(last_hidden_state.unsqueeze(dim = 0))[0]\n",
    "                low_dim_reps_prompt.append(low_dim_rep)\n",
    "\n",
    "            ranges_embedding = embedding_classifier._get_ranges_over_batch(sample_embedding[\"input_ids\"])[0]\n",
    "            range_last_hidden_states_embedding = torch.zeros((len(ranges_embedding),last_hidden_states_embedding.shape[-1]))\n",
    "            for idx, range_borders in enumerate(ranges_embedding):\n",
    "                range_ = torch.arange(range_borders[0], range_borders[1])\n",
    "                range_last_hidden_states_embedding[idx] = torch.mean(last_hidden_states_embedding[range_], dim=0)\n",
    "            # Convert to numpy arrays\n",
    "            range_last_hidden_states_embedding = range_last_hidden_states_embedding.detach().numpy()\n",
    "            low_dim_reps_embedding = []\n",
    "            all_low_dim_reps_embedding.append(low_dim_reps_embedding)\n",
    "            for pca, last_hidden_state in zip(embedding_pcas, last_hidden_states_embedding):\n",
    "                low_dim_rep = pca.transform(last_hidden_state.unsqueeze(dim = 0))[0]\n",
    "                low_dim_reps_embedding.append(low_dim_rep)\n",
    "    colors = cm.rainbow(np.linspace(0, 1, 5))\n",
    "    for sample, low_dim_reps_vanilla, low_dim_reps_prompt, low_dim_reps_embedding in zip(samples, all_low_dim_reps_vanilla,all_low_dim_reps_prompt, all_low_dim_reps_embedding):\n",
    "        user_id = sample[\"mappedUserId\"]\n",
    "        title = sample[\"title\"]\n",
    "        genres = sample[\"genres\"]\n",
    "        user_id_embedding_vanilla = low_dim_reps_vanilla[0]\n",
    "        title_embedding_vanilla = low_dim_reps_vanilla[1]\n",
    "        genres_embedding_vanilla = low_dim_reps_vanilla[2]\n",
    "\n",
    "        scatter_legend = []\n",
    "        if \"vanilla user\" in plot_filters:\n",
    "            v_u = plt.scatter([user_id_embedding_vanilla[0]], [user_id_embedding_vanilla[1]], marker=\"<\", color = colors[0])\n",
    "            scatter_legend.append(v_u)\n",
    "        if \"vanilla title\" in plot_filters:\n",
    "            v_t = plt.scatter([title_embedding_vanilla[0]], [title_embedding_vanilla[1]], marker=\"v\", color = colors[1])\n",
    "            scatter_legend.append(v_t)\n",
    "        if \"vanilla genres\" in plot_filters:\n",
    "            v_g = plt.scatter([genres_embedding_vanilla[0]], [genres_embedding_vanilla[1]], marker=\">\", color = colors[2])\n",
    "            scatter_legend.append(v_g)\n",
    "\n",
    "        \n",
    "        user_id_embedding_prompt = low_dim_reps_prompt[0]\n",
    "        title_embedding_prompt = low_dim_reps_prompt[1]\n",
    "        genres_embedding_prompt = low_dim_reps_prompt[2]\n",
    "        user_embedding_embedding_prompt = low_dim_reps_prompt[3]\n",
    "        movie_embedding_embedding_prompt = low_dim_reps_prompt[4]\n",
    "        if \"prompt user\" in plot_filters:\n",
    "            p_u = plt.scatter([user_id_embedding_prompt[0]], [user_id_embedding_prompt[1]], marker=\"s\", color = colors[0])\n",
    "            scatter_legend.append(p_u)\n",
    "        if \"prompt title\" in plot_filters:\n",
    "            p_t = plt.scatter([title_embedding_prompt[0]], [title_embedding_prompt[1]], marker=\"o\", color = colors[1])\n",
    "            scatter_legend.append(p_t)\n",
    "        if \"prompt genres\" in plot_filters:\n",
    "            p_g = plt.scatter([genres_embedding_prompt[0]], [genres_embedding_prompt[1]], marker=\"p\", color = colors[2])\n",
    "            scatter_legend.append(p_g)\n",
    "        if \"prompt user embedding\" in plot_filters:\n",
    "            p_ue = plt.scatter([user_embedding_embedding_prompt[0]], [user_embedding_embedding_prompt[1]], marker=\"P\", color = colors[3])\n",
    "            scatter_legend.append(p_ue)\n",
    "        if \"prompt movie embedding\" in plot_filters:\n",
    "            p_me = plt.scatter([movie_embedding_embedding_prompt[0]], [movie_embedding_embedding_prompt[1]], marker=\"*\", color = colors[4])\n",
    "            scatter_legend.append(p_me)\n",
    "        \n",
    "        \n",
    "        user_id_embedding_embedding = low_dim_reps_embedding[0]\n",
    "        title_embedding_embedding = low_dim_reps_embedding[1]\n",
    "        genres_embedding_embedding = low_dim_reps_embedding[2]\n",
    "        user_embedding_embedding_embedding = low_dim_reps_embedding[3]\n",
    "        movie_embedding_embedding_embedding = low_dim_reps_embedding[4]\n",
    "        if \"embedding user\" in plot_filters:\n",
    "            e_u = plt.scatter([user_id_embedding_embedding[0]], [user_id_embedding_embedding[1]], marker=\"1\", color = colors[0])\n",
    "            scatter_legend.append(e_u)\n",
    "        if \"embedding title\" in plot_filters:\n",
    "            e_t = plt.scatter([title_embedding_embedding[0]], [title_embedding_embedding[1]], marker=\"2\", color = colors[1])\n",
    "            scatter_legend.append(e_t)\n",
    "        if \"embedding genres\" in plot_filters:\n",
    "            e_g = plt.scatter([genres_embedding_embedding[0]], [genres_embedding_embedding[1]], marker=\"3\", color = colors[2])\n",
    "            scatter_legend.append(e_g)\n",
    "        if \"embedding user embedding\" in plot_filters:\n",
    "            e_ue = plt.scatter([user_embedding_embedding_embedding[0]], [user_embedding_embedding_embedding[1]], marker=\"4\", color = colors[3])\n",
    "            scatter_legend.append(e_ue)\n",
    "        if \"embedding movie embedding\" in plot_filters:\n",
    "            e_me = plt.scatter([movie_embedding_embedding_embedding[0]], [movie_embedding_embedding_embedding[1]], marker=\"x\", color = colors[4])\n",
    "            scatter_legend.append(e_me)\n",
    "    plt.legend(scatter_legend,\n",
    "            plot_filters,\n",
    "            scatterpoints=1,\n",
    "            loc='upper right',\n",
    "            ncol=3,\n",
    "            fontsize=8,)\n",
    "    plt.rcParams['figure.figsize'] = [8, 8]\n",
    "    plt.rcParams['figure.dpi'] = 100 # 200 e.g. is really fine, but slower\n",
    "    plt.figure(figsize=(8, 8), dpi=100)\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "n = 4\n",
    "all_filters = ['vanilla user', 'vanilla title', 'vanilla genres', 'prompt user', 'prompt title', 'prompt genres', 'prompt user embedding', 'prompt movie embedding', 'embedding user', 'embedding title', 'embedding genres', 'embedding user embedding', 'embedding movie embedding']\n",
    "only_user_filters = ['vanilla user', 'prompt user', 'embedding user']\n",
    "only_title_filters = ['vanilla title', 'prompt title', 'embedding title']\n",
    "only_genres_filters = ['vanilla genres', 'prompt genres', 'embedding genres']\n",
    "user_title_filters = ['vanilla user', 'vanilla title', 'prompt user', 'prompt title', 'embedding user', 'embedding title']\n",
    "embedding_filters = ['prompt user embedding', 'prompt movie embedding', 'embedding user embedding', 'embedding movie embedding']\n",
    "vanilla_filters =  ['vanilla user', 'vanilla title', 'vanilla genres','prompt user', 'prompt title', 'prompt genres','embedding user', 'embedding title', 'embedding genres']\n",
    "plot_filters = vanilla_filters\n",
    "singular_user = False\n",
    "singular_title = False\n",
    "plot_hidden_states_with_pca(vanilla_bert_only_classifier, prompt_bert_only_classifier, adding_embedding_bert_only_classifier, vanilla_pcas, prompt_pcas, embedding_pcas, gnn_trainer_prompt.get_embedding, gnn_trainer_adding.get_embedding, n = n, plot_filters = plot_filters, singular_user=singular_user, singular_title=singular_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "grundprojekt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
